{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainieren des Sentimentmodells\n",
    "\n",
    "In diesem Notebook wird ein Modell trainiert, welches Tweets live auf ihre Stimmung bewerten soll. Dafür wird ein Deep Neural Network erstellt, welches mit 1.6 Millionen Tweets trainiert wird. Hierbei handelt es sich um ein Klassifikationsproblem, es soll letztendlich entschieden werden, ob ein Tweet negativ (0), oder positiv (1) gestimmt ist.\n",
    "\n",
    "### Technologien\n",
    "\n",
    "Für das Modell wird [Tensorflow](https://www.tensorflow.org/) verwendet, zum plotten von Informationen nutzen wir [Matplotlib](https://matplotlib.org/stable/index.html) und zum verarbeiten von Daten [Pandas](https://pandas.pydata.org/). Weiterhin werden weitere utilities von [sklearn](https://scikit-learn.org/stable/) übernommen.\n",
    "\n",
    "### Setup\n",
    "\n",
    "Um dieses Notebook zu benutzen müssen Python 3.x und folgende Packages installiert werden:\n",
    "\n",
    "* tensorflow\n",
    "* matplotlib\n",
    "* pandas\n",
    "* sklearn\n",
    "\n",
    "Das Datenset fürs trainieren kann über [diesen Link](https://www.dropbox.com/s/ur7pw797mgcc1wr/tweets.csv?dl=0) heruntergeladen werden. Dabei muss die Datei \"tweets.csv\" in diesen Ordner abgelegt werden.\n",
    "\n",
    "### Datenset\n",
    "\n",
    "Um nun das Modell möglichst gut darauf zu trainieren reale Tweets zu bewerten haben wir uns für ein Datenset entschieden, welches 1.6 Millionen bereits gelabelte Tweets enthält, dieses kann [hier](https://www.kaggle.com/kazanova/sentiment140) gefunden werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden des Datensets\n",
    "\n",
    "Mithilfe von pandas wird das Datenset geladen, dabei werden nur die erste und die letzte Spalte geladen, da nur diese für uns von Interesse sind. Da es sich bei der ersten Spalte um die Stimmung des Tweets handelt wird diese mit \"targets\" gelabelt, die letzte Spalte beihaltet den eigentlichen Tweet, diese wird mit \"text\" gelabelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"./tweets.csv\", usecols=[0, 5], names=[\"target\", \"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da das Datenset sortiert ist muss es randomisiert werden. Falls dies nicht gemacht werden würde, hätte dies einen negativen Einfluss auf das Lernen, da alle Daten die zuerst reinkommen negativ gelabelt sind. Somit würde das Modell denken, alles wäre negativ und würde sich entsprechend darauf einstellen, kommen dann letztendlich alle positiven Daten würde das Modell denken es gäbe nur positive Daten und würde letztendlich bei richtigen Daten immer eine positive Stimmung predicten, was nicht der Realtität entsprechen würde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = shuffle(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum validieren, dass das Datenset auch korrekt geladen wurde, es sollte eine Tabelle mit den ersten fünf Einträgen zu sehen sein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1039256</th>\n",
       "      <td>4</td>\n",
       "      <td>Britney Spears is on SNL on E! right now. Damn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004874</th>\n",
       "      <td>4</td>\n",
       "      <td>@GuyHagi LOL Big Island suffers again. Hoping ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515991</th>\n",
       "      <td>0</td>\n",
       "      <td>I thought my cup of tea had been there longer....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532503</th>\n",
       "      <td>4</td>\n",
       "      <td>@vtmaroon7 Ever been to the antiques roadshow?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12450</th>\n",
       "      <td>0</td>\n",
       "      <td>@Hapson never tried it  you'll have to let me ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text\n",
       "1039256       4  Britney Spears is on SNL on E! right now. Damn...\n",
       "1004874       4  @GuyHagi LOL Big Island suffers again. Hoping ...\n",
       "515991        0  I thought my cup of tea had been there longer....\n",
       "1532503       4  @vtmaroon7 Ever been to the antiques roadshow?...\n",
       "12450         0  @Hapson never tried it  you'll have to let me ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das trainieren des Modells zu überwachen und um die Accuracy des Modells hinterher zu errechnen wird das Datenset in drei Teile unterteilt. In einem Verhältnis von 80:20 wird das Datenset in Trainingsdaten und Testdaten unterteilt. Trainingsdaten dienen hier ausschließlich zum trainieren des Modells, Testdaten werden nach dem Trainieren dazu verwendet, um die Accuracy des Modells zu errechnen, diese sollen reale Daten simulieren. Der Grund, warum das Verhältnis stark auf der Seite der Trainingsdaten liegt, ist, weil mehr Trainingsdaten ein besseres Ergebnis versprechen, dabei muss die Anzahl der Daten bei den Testdaten nicht hoch sein, um die Accuracy zu bestimmen.\n",
    "\n",
    "Weiterhin werden die Trainingsdaten wiederum in Trainingsdaten und Validationsdaten mit einem Verhältnis von 80:20 unterteilt. Die Validationsdaten werden dazu verwendet um das Training zu überwachen, nach jedem Epoch (Trainingsschritt) wird damit die aktuelle Accuracy bestimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024000 training tweets\n",
      "256000 validation tweets\n",
      "320000 test tweets\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "\n",
    "print(len(train), 'training tweets')\n",
    "print(len(val), 'validation tweets')\n",
    "print(len(test), 'test tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da jetzt das Datenset entsprechend aufgeteilt wurde kann es nun in das verlangte Tensorflowformat gebracht werden. Dafür werden die Features (text) und die Labels (labels) klar definiert. Zusätzlich wird eine Batchsize definiert, welche Daten gruppiert um das Lernen zu beschleunigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, batch_size):\n",
    "  dataframe = dataframe.copy()\n",
    "  texts = dataframe.pop('text')\n",
    "  labels = dataframe.pop('target')\n",
    "  return tf.data.Dataset.from_tensor_slices((texts, labels)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 320\n",
    "\n",
    "raw_train_ds = df_to_dataset(train, batch_size)\n",
    "raw_val_ds = df_to_dataset(val, batch_size)\n",
    "raw_test_ds = df_to_dataset(test, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um zu validieren, dass die Konvertierung geklappt hat werden die ersten drei Einträge ausgelesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: b'We are STILL not on the road '\n",
      "Label: 0\n",
      "Tweet: b\"@SmithToYou Well, based on what one of their employees just posted on my blog, Metro Bank isn't very people-friendly either.  \"\n",
      "Label: 0\n",
      "Tweet: b'Should look for more jobs at adidas...not feeling good about puma '\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "  for i in range(3):\n",
    "    print(\"Tweet:\", text_batch.numpy()[i])\n",
    "    print(\"Label:\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier werden die Daten für das Modell normalisiert. Dies ist wichtig um unnötige Duplikate zu vermeiden, wie z.B. Wörter, die in manchen Tweets groß und in anderen wieder klein geschrieben werden. Zusätzlich können Usernames, welche mit \"@\" beginnen normalisiert werden, da der genaue username unwichtig für die sentiment prediction ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  # todo: filter out usernames\n",
    "  usernames = tf.strings.regex_replace(lowercase, '@\"\\B@\\w+\"', 'user')\n",
    "  return tf.strings.regex_replace(usernames, '[%s]' % re.escape(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können die Texte vektorisiert werden. Da ein neuronales Netz nicht mir Wörtern und Buchstaben arbeiten kann, müssen diese in Zahlen umgewandelt werden. Dafür werden die Tweets in Vektoren umgewandelt. Die Größe des Vektors wird dabei mit sequence_length definiert. Die Größe der sequence_length, also letztendlich die Größe des Vektors sollte in der Regel so groß sein, dass alle Wörter eines Tweets hereinpassen. Da die Anzahl an Zeichen auf 280 pro Tweet limitiert ist, und die durschnittliche Anzahl der Zeichen pro Wort im Englischen bei 5 liegt wird die sequence_length mit 56 definiert.\n",
    "\n",
    "Hier erhält jedes Wort eine fortlaufende Id, die Reihenfolge wird darüber bestimmt, welche Wörter zuerst vektorisiert werden. Dabei können aufgrund max_features maximal 10000 Wörter eingelesen werden, alle weiteren werden ignoriert, diese Menge an Vokabeln sollte aber ausreichen, da in der Alltagssprache lediglich zwei bis drei tausend Wörter verwendet werden. Somit kann jedes Wort zu einer Id gemappt werden, sodass man letztendlich ganze Sätze in einem Vektor abbilden kann. Damit lösen wir auch das Problem, dass ein neuronales Netz immer die gleiche Inputgröße benötigt, da die Vektorengröße immer der sequence_length enstpricht.\n",
    "\n",
    "Dafür wird hier ein Vektorlayer erstellt. Gleichzeitig können hier die Daten normalisiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 56\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=normalize_data,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier werden die Trainingsdaten eingelesen, sodass die 10000 features gefüllt werden können, somit haben wir für die Tweets ein eigenes \"Wörterbuch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Tensorflow type 21 not convertible to numpy dtype.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-8358643f2401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvectorize_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'store'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2305\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2306\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2307\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2308\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</usr/local/lib/python3.7/site-packages/decorator.py:decorator-gen-125>\u001b[0m in \u001b[0;36mstore\u001b[0;34m(self, parameter_s)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/IPython/extensions/storemagic.py\u001b[0m in \u001b[0;36mstore\u001b[0;34m(self, parameter_s)\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;31m#pickled = pickle.dumps(obj)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m'autorestore/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stored '%s' (%s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pickleshare.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# and Python 3. We can upgrade to protocol 3 when Python 2 is obsolete.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfil\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__reduce__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__copy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1037\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Tensorflow type 21 not convertible to numpy dtype."
     ]
    }
   ],
   "source": [
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Methode können wir gleich alle Datensets vektorisieren. Hier normalisieren wir noch das Label, sodass das Label eine Range von 0 bis 1, anstatt von 0 bis 4 hat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return vectorize_layer(text), int(label / 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um zu testen, ob das vektorisieren der Tweets funktioniert können wir den ersten Tweet aus dem ersten Batch auslesen und vektorisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'We are STILL not on the road ', shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "(<tf.Tensor: shape=(1, 56), dtype=int64, numpy=\n",
      "array([[ 59,  37,  69,  26,  15,   4, 905,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0]])>, 0)\n"
     ]
    }
   ],
   "source": [
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "text, label = text_batch[0], label_batch[0]\n",
    "print(text)\n",
    "print(label)\n",
    "print(vectorize_text(text, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe des Vektorlayers können wir die Ids wieder zu Wörtern zurückmappen, außerdem können wir die Größe unseres Wörterbuchs auslesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234 --->  quot\n",
      "Vocabulary size: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"1234 ---> \", vectorize_layer.get_vocabulary()[1234])\n",
    "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun vektorisieren wir alle benötigten Datensets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus Performancegründen können die Datensets weiter aufbereitet werden. Mit `.cache()` bleiben die Daten im Arbeitsspeicher, nachdem diese von der Festplatte geladen wurden. Somit kann sichergestellt werden, dass das Laden der Daten nicht das Bottleneck beim Training sein wird.\n",
    "\n",
    "Mit `.prefetch()` können die Daten gleichzeitig mit dem Lernen präprozessiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schließlich definieren wir das eigentliche Modell. Die erste Layer ist ein Embedding-Layer. Dies sorgt dafür, dass jedes Wort wiederum einen eigenen Vektor erhält, dieser stellt die Bedeutung des Wortes dar. Diese Vektoren werden mit dem Modell mit der Zeit trainiert. Diese Embeddinglayer fügt eine weitere Dimension zum Outputvektor hinzu. Hier definieren wir mit der embedding_dim die Größe der Layers, das bedeutet, dass es 32 Nodes pro Layer gibt.\n",
    "\n",
    "Für die nächste Layer wird `GlobalAveragePooling1D` verwendet. Diese reduziert die Dimension wieder um 1 und verrechnet dabei alle Informationen, sodass nichts verloren geht. Der Outputvektor wird dabei wieder auf eine feste Länge normalisiert.\n",
    "\n",
    "Anschließend folgt ein fully-connected 32 Dense-Layer. Hier wurde eine Dropoutrate festgelegt, um Overfitting zu verhindern. Das Ziel hier ist random ausgewählte Nodes auf 0 zu setzen, damit das anspassen der Weights der einzelnen Nodes beim lernen gefördert wird.\n",
    "\n",
    "Letztendlich wird das letzte Layer mit einem Dense Layer zu einer einzigen Node verknüpft. Diese hat eine Range von 0 bis 1 und gibt das Ergenis aus.\n",
    "\n",
    "Wir können nun noch mit `.summary()` das Modell verifizieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 32)          320032    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 320,065\n",
      "Trainable params: 320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 32\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Embedding(max_features + 1, embedding_dim),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das Trainieren müssen noch ein paar Parameter definiert werden. Für die Berechnung des Fehlers (loss) verwenden wir die `BinaryCrossentropy` Funktion. Der Fehler gibt uns an, wie weit wir von der richtigen Prediction weg sind. Wir haben uns dafür entschieden, da wir einen sogenannten Binary Classifier haben, der uns eine Wahrscheinlichkeit von 0 bis 1 als Ergebnis gibt. Dabei arbeiten wir mit Logits, sodass die Labels als sogennante Logits betrachtet werden, diese Darstellung als Wahrscheinlichkeit verspricht laut Tensorflow größere numerische Stabilität.\n",
    "\n",
    "Weiterhin verwenden wir für den Optimierungsalgorithmus den `Adam-Optimizer`. Wir haben uns für den Adam-Optimizer, im Gegensatz zum klassischen Stochastic Gradient Descent Algorithmus entschieden, da sich die Learningrate beim Adam-Optimizer mit der Zeit automatisch anpasst. Das ist besonders praktisch bei Natural Language Processing, da hier die Gradients in der Regel sehr gering sind. Dabei wird die Learningrate basierend auf der vorherigen Änderung der Weights angepasst. Hier haben wir eine sehr kleine Learningrate definiert, da wir ein sehr großes Datenset haben und nicht zu schnell in das Problem von Overfitting laufen wollen, weshalb langsameres lernen, also ein langsameres Anpassen der Weights, hier passender ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wird endlich das Modell trainiert. Dafür definieren wir mit epochs, wie oft wir über das Trainingsdatenset iterieren. Es werden in `model.fit()` die Trainingsdaten, die Validationsdaten und die Anzahl der Epochen angegeben. Tensorflow loggt den Fortschritt live in der Konsole aus, zusätzlich wird der Trainingsstatus in einem History-Objekt festgehalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3200/3200 [==============================] - 15s 5ms/step - loss: 0.6850 - binary_accuracy: 0.6088 - val_loss: 0.6451 - val_binary_accuracy: 0.7030\n",
      "Epoch 2/10\n",
      "3200/3200 [==============================] - 13s 4ms/step - loss: 0.6299 - binary_accuracy: 0.7104 - val_loss: 0.5887 - val_binary_accuracy: 0.7298\n",
      "Epoch 3/10\n",
      "3200/3200 [==============================] - 11s 3ms/step - loss: 0.5780 - binary_accuracy: 0.7352 - val_loss: 0.5488 - val_binary_accuracy: 0.7511\n",
      "Epoch 4/10\n",
      "3200/3200 [==============================] - 10s 3ms/step - loss: 0.5413 - binary_accuracy: 0.7552 - val_loss: 0.5208 - val_binary_accuracy: 0.7662\n",
      "Epoch 5/10\n",
      "3200/3200 [==============================] - 11s 3ms/step - loss: 0.5157 - binary_accuracy: 0.7685 - val_loss: 0.5022 - val_binary_accuracy: 0.7751\n",
      "Epoch 6/10\n",
      "3200/3200 [==============================] - 13s 4ms/step - loss: 0.4985 - binary_accuracy: 0.7771 - val_loss: 0.4903 - val_binary_accuracy: 0.7806\n",
      "Epoch 7/10\n",
      "3200/3200 [==============================] - 13s 4ms/step - loss: 0.4875 - binary_accuracy: 0.7823 - val_loss: 0.4828 - val_binary_accuracy: 0.7845\n",
      "Epoch 8/10\n",
      "3200/3200 [==============================] - 11s 3ms/step - loss: 0.4802 - binary_accuracy: 0.7859 - val_loss: 0.4779 - val_binary_accuracy: 0.7872\n",
      "Epoch 9/10\n",
      "3200/3200 [==============================] - 11s 4ms/step - loss: 0.4754 - binary_accuracy: 0.7885 - val_loss: 0.4746 - val_binary_accuracy: 0.7889\n",
      "Epoch 10/10\n",
      "3200/3200 [==============================] - 12s 4ms/step - loss: 0.4720 - binary_accuracy: 0.7905 - val_loss: 0.4721 - val_binary_accuracy: 0.7900\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem das Modell nur trainiert ist können wir es mit den vorher festgelegten Testdatensatz testen. Diese sollen wie bereits erwähnt echte Daten simulieren. Dabei erhalten wir mit `model.evaluate()` den Loss und die Accuracy, welche bei rund 80% liegt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4710 - binary_accuracy: 0.7898\n",
      "Loss:  0.47095298767089844\n",
      "Accuracy:  0.7898187637329102\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dem History-Objekt können wir nun sehen, welche Daten Tensorflow für uns aufgezeichnet hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe von Matplotlib können wir den Loss plotten und beobachten, wie diese sich beim lernen verhalten hat. Optimalerweise sollte diese mit der Zeit runtergehen, da mit dem Anpassen der Weights das Modell immer genauere Aussagen treffen sollte und somit der Fehler immer geringer wird.\n",
    "\n",
    "Wir können erkennen, dass dies tatsächlich der Fall ist, dabei fällt der Loss fast exponentiell. Logischerweise wird der Trainingsloss immer geringer, als Bestätigung für die Verbesserung des Modells dient hier die Validationloss. Diese ist fast gleich, sodass wir davon ausgehen können, dass die Anzahl der Fehlinterpretierungen tatsächlich geringer wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'o', color='orange', label='Training Loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'blue', label='Validation Loss')\n",
    "plt.title('Trainings- und Validationsloss')\n",
    "plt.xlabel('Epochen')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das gleiche können wir auch für die Accuracy machen. Hier sollte im Optimalfall die Accuracy mit der Zeit steigen. Dieses Verhalten können wir wieder an unserem Modell erkennen. Hier erinnert der Graph an eine Sättigungskurve. Das liegt daran, dass es mit der Zeit immer schwerer wird das Modell noch mehr zu verbessern, da das Lernen letztendlich eine Optimierung ist, dessen Verbesserung im späteren Verlauf nur mit höheren Aufwänden zu erreichen ist.\n",
    "\n",
    "An beiden Graphiken kann man jedoch gut erkennen, dass es zu keinem Overfitting kommt. Wenn wir die Accuracy betrachten, würde bei Overfitting die Accuracy der Testdaten weiter Ansteigen, während die Accuracy der Validationsdaten und die der Testdaten stagniert oder gar heruntergeht. Das gleiche würde analog mit dem Loss passieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'o', color='orange', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'blue', label='Validation Accuracy')\n",
    "plt.title('Trainings- und Validationsaccuracy')\n",
    "plt.xlabel('Epochen')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun exportieren wir das fertige Modell. Da wir vorher die Texte vektorisiert haben, bevor sie in das Modell gegeben wurden, können wir hier ein Modell exportieren, welche die Texte beim Input vektorisiert. Dies macht uns jetzt das zukünftige Predicten einfacher. Zusätzlich fügen wir am Ende eine weitere Node mit einer Sigmoid Aktivierungsfunktion hinzu. Diese mappt uns alle Werte zwischen 0 und 1, sodass unsere definiert Sentiment Range eingehalten wird. Die Vektorisationlayer und die Sigmoid Node wurden beim lernen weggelassen, um die Effizienz zu erhöhen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model = tf.keras.Sequential([\n",
    "  vectorize_layer,\n",
    "  model,\n",
    "  layers.Activation('sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schließlich können wir ein paar Beispiele eingeben um zu sehen, was das Modell denkt. Dabei ist der erste Satz positiv, der zweite neutral und der letzte negativ. Anhand der Ergebnisse können wir sehen, dass das Modell ähnlich darüber denkt. Während der neutrale Satz mit rund 0.5 gewertet wird, wird der positive höher gewertet und der negative geringer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7698233 ],\n",
       "       [0.5183914 ],\n",
       "       [0.24242812]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\n",
    "  \"Today is a great day!\",\n",
    "  \"This sentence is rather neutral\",\n",
    "  \"This show is terrible!\"\n",
    "]\n",
    "\n",
    "sentiment_model.predict(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# technical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwenden auf Twitter Livedaten\n",
    "\n",
    "blablabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searchtweets import load_credentials, gen_request_parameters, collect_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
